{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: openai in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (1.25.0)\n",
      "Requirement already satisfied: python-dotenv in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: praw in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (7.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Requirement already satisfied: colorama in d:\\projects\\local\\new folder\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\\\n",
    "%pip install requests openai python-dotenv praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../code')\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Now you can access the variables using os.getenv\n",
    "gpt4_azure_openai_endpoint = os.getenv(\"GPT4_AZURE_OPENAI_ENDPOINT\")\n",
    "gpt4_azure_openai_key = os.getenv(\"GPT4_AZURE_OPENAI_KEY\")\n",
    "gpt4_azure_openai_api_version = os.getenv(\"GPT4_AZURE_OPENAI_API_VERSION\")\n",
    "gpt4_deployment_name = os.getenv(\"GPT4_DEPLOYMENT_NAME\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init tool array\n",
    "\n",
    "tools = []\n",
    "functions_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reddit_functions import RedditClient\n",
    "\n",
    "reddit = RedditClient()\n",
    "\n",
    "fucntions = reddit.get_function_descriptions()\n",
    "\n",
    "for f in fucntions:\n",
    "    tools.append(f)\n",
    "\n",
    "functions_map['subreddit_search'] = reddit.subreddit_search\n",
    "functions_map['get_reddit_posts'] = reddit.get_reddit_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_fucntions import FileFunctions\n",
    "\n",
    "file_functions = FileFunctions()\n",
    "functions = file_functions.get_function_descriptions()\n",
    "for f in functions:\n",
    "    tools.append(f)\n",
    "\n",
    "functions_map[\"write_to_file\"] = file_functions.write_to_file\n",
    "functions_map[\"read_file\"] = file_functions.read_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.append({\"type\": \"code_interpreter\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_def = {\n",
    "    'name' : \"reddit_assistant\",\n",
    "     'instructions' : \"\"\"You are an assistant designed to help users getting an overview what happens on a subreddit.\n",
    "\n",
    "You have access to the subreddit api and create a newsletter like summary the top posts of a subreddit for the user.\n",
    "\"\"\",\n",
    "'model': gpt4_deployment_name,\n",
    "'azure_openai_key': gpt4_azure_openai_key,\n",
    "'azure_openai_endpoint': gpt4_azure_openai_endpoint,\n",
    "'azure_openai_api_version': gpt4_azure_openai_api_version\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poll 0: queued\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m mikoAssistant \u001b[38;5;241m=\u001b[39m MikoAssistant(assistant_def, tools, functions_map)\n\u001b[0;32m      7\u001b[0m mikoAssistant\u001b[38;5;241m.\u001b[39mcreate_new_thread()\n\u001b[1;32m---> 10\u001b[0m messages \u001b[38;5;241m=\u001b[39m \u001b[43mmikoAssistant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOpen the file \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubreddits.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m and create a suammary of the top posts of each of the subreddits in the file in an.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m conversation \u001b[38;5;241m=\u001b[39m mikoAssistant\u001b[38;5;241m.\u001b[39mextract_message_content(messages, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m conversation:\n",
      "File \u001b[1;32md:\\Projects\\Local\\New folder\\reddit_sample\\../code\\MiKoAssistant.py:24\u001b[0m, in \u001b[0;36mMikoAssistant.send_message\u001b[1;34m(self, message, verbose_output)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_message(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, message)\n\u001b[0;32m     23\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mruns\u001b[38;5;241m.\u001b[39mcreate(thread_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthread\u001b[38;5;241m.\u001b[39mid, assistant_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massistant\u001b[38;5;241m.\u001b[39mid)\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll_run_till_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavailable_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctions_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve_messages()\n",
      "File \u001b[1;32md:\\Projects\\Local\\New folder\\reddit_sample\\../code\\MiKoAssistant.py:141\u001b[0m, in \u001b[0;36mMikoAssistant.poll_run_till_completion\u001b[1;34m(self, run_id, available_functions, verbose, max_steps, wait)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    140\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28mprint\u001b[39m(e)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from MiKoAssistant import MikoAssistant\n",
    "\n",
    "verbose_output = True\n",
    "\n",
    "mikoAssistant = MikoAssistant(assistant_def, tools, functions_map)\n",
    "\n",
    "mikoAssistant.create_new_thread()\n",
    "\n",
    "\n",
    "messages = mikoAssistant.send_message(\"Open the file 'subreddits.txt' and create a suammary of the top posts of each of the subreddits in the file in an.\", verbose_output)\n",
    "\n",
    "conversation = mikoAssistant.extract_message_content(messages, \"output\")\n",
    "for c in conversation:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = mikoAssistant.send_message(\"please save it in a file\", verbose_output)\n",
    "\n",
    "conversation = mikoAssistant.extract_message_content(messages, \"output\")\n",
    "for c in conversation:\n",
    "    print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
